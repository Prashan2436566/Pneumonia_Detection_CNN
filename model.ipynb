{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lucian Irsigler 2621933, Prashan Rajaratnam 2436566, Banzile Nhlebela 2571291, Pramit Kanji 2551233\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    "    random_split,\n",
    "    Subset,\n",
    "    WeightedRandomSampler\n",
    ")\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "We have the following hyperparameters:\n",
    "- num_epochs : Number of epochs to train on\n",
    "- batch_size : Number of images to be in each batch\n",
    "- image_size : square image size to resize images to\n",
    "- lr : learning rate\n",
    "- size : represents the TRAIN-VALIDATION-TEST split\n",
    "- balanced: Whether to use a WeightedRandomSampler or not for the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "h = {\n",
    "    \"num_epochs\": 10,\n",
    "    \"batch_size\": 64,\n",
    "    \"image_size\": 56,\n",
    "    \"lr\": 0.001,\n",
    "    \"size\":(0.6,0.2,0.2),\n",
    "    \"balanced\":True\n",
    "}\n",
    "\n",
    "classes = (\"NORMAL\",\"PNEUMONIA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preventing Data leakage\n",
    "In the PNEUMONIA data, there exists files such as \"personx_bacteria0\",\"personx_bacteria1\"...\n",
    "These are multiple scans for the same person.\n",
    "\n",
    "If left as is, there is a potential for the same person's scans to be in multiple data sets, eg) 1 file in test, another in train.\n",
    "\n",
    "This gives an inflated evaluation metric. Hence we ensure that the files for a person only appears in one data set.\n",
    "\n",
    "We do this as follows:\n",
    "- Extract all the unique person's IDs from the PNEUMONIA files into a list\n",
    "- Shuffle the IDs\n",
    "- Split the list into the data split specified by the \"size\" hyperparameter\n",
    "- Find the relevent files with that id, and add to test,validation or train set for PNEUMONIA\n",
    "- Return the lists\n",
    "\n",
    "Since we have a weird way of loading data, we have a custom wrapper to feed to a Dataloader. This class **CustomImageDataset**, simply takes in a list of images and associates a class to them based on the path of that image (\"NORMAL\" in path is class 0 and \"PNEUMONIA\" in path is class 1).\n",
    "\n",
    "This CustomImageDataset allows us to split all the PNEUMONIA files as specified above, and to split the NORMAL images as usual.\n",
    "\n",
    "Lastly, there is a Data Leakage check, that just checks that all the PNEUMONIA files, if one of a person's files is in a dataset, that all of them are there.\n",
    "\n",
    "eg) if id x is found in test, it should NOT be found in train/validation. If found, then a data leakage has occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patient_ids(filename):\n",
    "    patient_id = filename.split('_')[0].replace(\"person\", \"\")\n",
    "    return patient_id\n",
    "\n",
    "\n",
    "def split_file_names(h,folder=\"chest\", seed=42):\n",
    "    random.seed(seed)  # For reproducibility\n",
    "    location = os.path.join(folder, \"PNEUMONIA\")\n",
    "\n",
    "    # Get unique patient IDs\n",
    "    pneumonia_patient_ids = list(set([extract_patient_ids(fn) for fn in os.listdir(location)]))\n",
    "    total_patients = len(pneumonia_patient_ids)\n",
    "\n",
    "    # Shuffle and split\n",
    "    random.shuffle(pneumonia_patient_ids)\n",
    "    train_cutoff = int(h[\"size\"][0] * total_patients)\n",
    "    val_cutoff = int((1-h[\"size\"][1]) * total_patients)\n",
    "\n",
    "    train_ids = set(pneumonia_patient_ids[:train_cutoff])\n",
    "    val_ids = set(pneumonia_patient_ids[train_cutoff:val_cutoff])\n",
    "    test_ids = set(pneumonia_patient_ids[val_cutoff:])\n",
    "\n",
    "    # Initialize file path lists\n",
    "    train_files, val_files, test_files = [], [], []\n",
    "\n",
    "    for fn in os.listdir(location):\n",
    "        patient_id = extract_patient_ids(fn)\n",
    "        full_path = os.path.join(location, fn)\n",
    "\n",
    "        if patient_id in train_ids:\n",
    "            train_files.append(full_path)\n",
    "        elif patient_id in val_ids:\n",
    "            val_files.append(full_path)\n",
    "        elif patient_id in test_ids:\n",
    "            test_files.append(full_path)\n",
    "\n",
    "    # print(f\"Train: {len(train_files)}\\nValidation: {len(val_files)}\\nTest: {len(test_files)}\")\n",
    "    return train_files, val_files, test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.label_map = {\"NORMAL\": 0, \"PNEUMONIA\": 1}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        \n",
    "        # Infer label from file path\n",
    "        if \"NORMAL\" in path:\n",
    "            label = self.label_map[\"NORMAL\"]\n",
    "        elif \"PNEUMONIA\" in path:\n",
    "            label = self.label_map[\"PNEUMONIA\"]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown class in file path: {path}\")\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {path}: {e}\")\n",
    "            # Return a blank image as fallback\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_indices(self):\n",
    "        \"\"\"Return all valid indices for this dataset\"\"\"\n",
    "        return list(range(len(self.image_paths)))\n",
    "    \n",
    "    def get_image_label_pairs(self):\n",
    "        \"\"\"Return list of tuples (img_path, class_label) for all images\"\"\"\n",
    "        pairs = []\n",
    "        for path in self.image_paths:\n",
    "            if \"NORMAL\" in path:\n",
    "                label = self.label_map[\"NORMAL\"]\n",
    "            elif \"PNEUMONIA\" in path:\n",
    "                label = self.label_map[\"PNEUMONIA\"]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown class in file path: {path}\")\n",
    "            pairs.append((path, label))\n",
    "        return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDataLeakage(trainLoader, valLoader, testLoader) -> bool:\n",
    "    location = os.path.join(\"chest\", \"PNEUMONIA\")\n",
    "    pneumonia_files = os.listdir(location)\n",
    "    pneumonia_patient_ids = list(set([extract_patient_ids(fn) for fn in pneumonia_files]))\n",
    "    total_patients = len(pneumonia_patient_ids)\n",
    "    print(f\"Total unique PNEUMONIA patients: {total_patients}\")\n",
    "\n",
    "    leaked = False\n",
    "\n",
    "    for patient_id in pneumonia_patient_ids:\n",
    "        pattern = re.compile(rf'person{patient_id}(?!\\d)') \n",
    "\n",
    "        train_files = [path for path in trainLoader.dataset.image_paths if pattern.search(path)]\n",
    "        val_files = [path for path in valLoader.dataset.image_paths if pattern.search(path)]\n",
    "        test_files = [path for path in testLoader.dataset.image_paths if pattern.search(path)]\n",
    "\n",
    "        if sum(map(bool, [train_files, val_files, test_files])) > 1:\n",
    "            print(f\"\\nData leakage detected for patient ID: {patient_id}\")\n",
    "            print(f\"  → In train: {len(train_files)} file(s)\")\n",
    "            for f in train_files:\n",
    "                print(f\"    - {f}\")\n",
    "            print(f\"  → In val: {len(val_files)} file(s)\")\n",
    "            for f in val_files:\n",
    "                print(f\"    - {f}\")\n",
    "            print(f\"  → In test: {len(test_files)} file(s)\")\n",
    "            for f in test_files:\n",
    "                print(f\"    - {f}\")\n",
    "            leaked = True\n",
    "\n",
    "    if not leaked:\n",
    "        print(\"No data leak present\")\n",
    "    return leaked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and split\n",
    "This section includes the files for:\n",
    "- Creating a WeightedRandomSampler\n",
    "- loading the data from file using pytorch's ```ImageFolder``` object\n",
    "- Splitting the data into the train-validation-test data sets\n",
    "- Creating the ```DataLoader``` for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weighted_sampler(dataset):\n",
    "    targets = [label for _,label in dataset]\n",
    "    class_counts = np.bincount(targets)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    class_weights = class_weights / class_weights.sum()\n",
    "    weights = [class_weights[label] for label in targets]\n",
    "    sampler = WeightedRandomSampler(weights,len(weights))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder=\"chest\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((h[\"image_size\"],h[\"image_size\"])),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    full_dataset = datasets.ImageFolder(folder,transform=transform)\n",
    "\n",
    "    return full_dataset\n",
    "\n",
    "\n",
    "def splitData(dataset,h):\n",
    "    if (sum(h[\"size\"])!=1.0):\n",
    "        raise ValueError(\"Need to equal 1\")\n",
    "    \n",
    "    train_size = int(h[\"size\"][0]*len(dataset))\n",
    "    val_size = int(h[\"size\"][1]*len(dataset))\n",
    "    test_size = len(dataset)-val_size-train_size\n",
    "\n",
    "    train_data,val_data,test_data = random_split(dataset,[train_size,val_size,test_size])\n",
    "\n",
    "    return train_data,val_data,test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalIndices(dataset):\n",
    "    normal_indices = [i for i, (path, label) in enumerate(dataset.imgs) if \"NORMAL\" in path]\n",
    "    return normal_indices\n",
    "\n",
    "\n",
    "def splitNormalData(dataset,indices):\n",
    "    normal_dataset = Subset(dataset, indices)\n",
    "    train_data, val_data, test_data = splitData(normal_dataset, h)\n",
    "    return train_data,val_data,test_data\n",
    "\n",
    "\n",
    "def getNormalFiles(dataset,trainData,valData,testData):\n",
    "    train_files = [dataset.imgs[idx][0] for idx in trainData.indices]\n",
    "    val_files = [dataset.imgs[idx][0] for idx in valData.indices]\n",
    "    test_files = [dataset.imgs[idx][0] for idx in testData.indices]\n",
    "    return train_files,val_files,test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineFiles(normalFiles,pneumoniaFiles):\n",
    "    if (len(normalFiles))!=len(pneumoniaFiles):\n",
    "        raise ValueError(\"normalFiles and pneumoniaFiles must match in size\")\n",
    "\n",
    "    finalTestFiles = normalFiles[0]+pneumoniaFiles[0]\n",
    "    finalValFiles = normalFiles[1]+pneumoniaFiles[1]\n",
    "    finalTrainFiles = normalFiles[2]+pneumoniaFiles[2]\n",
    "\n",
    "    return finalTestFiles,finalValFiles,finalTrainFiles\n",
    "\n",
    "\n",
    "def createDataLoaders(train_data,val_data,test_data,batch_size,balanced=False):\n",
    "    if balanced:\n",
    "        sampler = create_weighted_sampler(train_data)\n",
    "        train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                    batch_size=h[\"batch_size\"], \n",
    "                    sampler=sampler, \n",
    "                    num_workers=4)\n",
    "    else: \n",
    "        train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True)\n",
    "    test_loader = DataLoader(test_data,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    return train_loader,val_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the data loaders\n",
    "def load_pipeline(h):\n",
    "    dataset = load_data()\n",
    "\n",
    "    #NORMAL data stuff\n",
    "    normal_indices = getNormalIndices(dataset)\n",
    "    train_data, val_data, test_data = splitNormalData(dataset,normal_indices)\n",
    "    n_train_files,n_val_files,n_test_files = getNormalFiles(dataset,train_data,val_data,test_data)\n",
    "\n",
    "    #PNEUMONIA data stuff\n",
    "    p_train_files, p_val_files, p_test_files = split_file_names(h)\n",
    "\n",
    "    train_files,val_files,test_files = combineFiles([n_train_files,n_val_files,n_test_files],\n",
    "                                                    [p_train_files,p_val_files,p_test_files])\n",
    "    \n",
    "    # Create custom datasets\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((h[\"image_size\"],h[\"image_size\"])),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    train_dataset = CustomImageDataset(train_files, transform=transform)\n",
    "    val_dataset = CustomImageDataset(val_files, transform=transform)\n",
    "    test_dataset = CustomImageDataset(test_files, transform=transform)\n",
    "\n",
    "    #Create data loaders\n",
    "    train_loader,val_loader,test_loader=createDataLoaders(train_dataset,val_dataset,\n",
    "                                                    test_dataset,h[\"batch_size\"],h[\"balanced\"])\n",
    "    \n",
    "    \n",
    "    return train_loader,val_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,val_loader,test_loader=load_pipeline(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = checkDataLeakage(train_loader,val_loader,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other\n",
    "This section has an optional way to just show 4 images from the train_loader. This was just for visual purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showImages(train_loader):\n",
    "    images, labels = next(iter(train_loader))\n",
    "    for i in range(4):\n",
    "        imshow(images[i], title=f\"Label: {labels[i].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data analysis\n",
    "\n",
    "Observations:\n",
    "- The classes are biased. There are 4273 PNEUMONIA images and 1583 NORMAL images. The dataset is thus 73% PNEUMONIA and 27% NORMAL.\n",
    "\n",
    "We visualize the difference in classes(per data set) using graphs below, and we also calculate their mean/std per data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_class_dist(loader,dataset_name):\n",
    "    class_counts = np.zeros(2)\n",
    "    for _,y in loader.dataset.get_image_label_pairs():\n",
    "        class_counts[y]+=1\n",
    "    \n",
    "    print([(classes[i],class_counts[i]) for i in range(len(classes))])\n",
    "    plt.bar([\"Normal\",\"Pneumonia\"],class_counts)\n",
    "    plt.xlabel(\"Classes\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Class distribtion in {dataset_name} data\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_stats(dataset):\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "\n",
    "    for x,_ in dataset:\n",
    "        mean+=x.mean()\n",
    "        std+=x.std()\n",
    "\n",
    "    mean /= len(dataset)\n",
    "    std /= len(dataset)\n",
    "\n",
    "    return mean.item(),std.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classes(trainLoader,valLoader,testLoader):\n",
    "    vis_class_dist(trainLoader,\"Train\")\n",
    "    mean,std = calculate_stats(trainLoader)\n",
    "    print(f\"Train dataset mean and std:{mean},{std}\")\n",
    "\n",
    "    vis_class_dist(valLoader,\"Validation\")\n",
    "    mean1,std1 = calculate_stats(valLoader)\n",
    "    print(f\"Validation dataset mean and std:{mean1},{std1}\")\n",
    "\n",
    "    vis_class_dist(testLoader,\"Test\")\n",
    "    mean2,std2 = calculate_stats(testLoader)\n",
    "    print(f\"Test dataset mean and std:{mean2},{std2}\")\n",
    "\n",
    "    return [mean,mean1,mean2],[std,std1,std2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classes(train_loader,val_loader,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image_size,dataset:torch.utils.data.dataloader.DataLoader,means,std):\n",
    "    data_tranforms = transforms.Compose([\n",
    "        transforms.Resize([image_size,image_size]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=means,std=std)\n",
    "    ])\n",
    "\n",
    "    #TODO change some numbers here\n",
    "    data_tranforms_train = transforms.Compose([\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomResizedCrop(size=[image_size,image_size],scale=(0.8,1.0)),\n",
    "        transforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.1,hue=0.1),\n",
    "        transforms.Resize(size=[image_size,image_size]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=means,std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = [mean,mean1,mean2]\n",
    "# stds = [std,std1,std2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture Overview\n",
    "\n",
    "This Convolutional Neural Network (CNN) is designed for classifying NORMAL vs PNEUMONIA on RGB images of size 52×52\n",
    "\n",
    "###  Architecture Details\n",
    "\n",
    "- **Input:**  \n",
    "  `3 × 52 × 52` RGB image\n",
    "\n",
    "1. **Conv Layer 1**  \n",
    "   - Channels: `3 → 16`  \n",
    "   - Kernel Size: `3 × 3`, Padding: `1`  \n",
    "   - Components:  \n",
    "     - Batch Normalization  \n",
    "     - ReLU Activation  \n",
    "     - MaxPooling: `2 × 2`  \n",
    "     - Dropout2D: `p = 0.5`\n",
    "\n",
    "2. **Conv Layer 2**  \n",
    "   - Channels: `16 → 32`  \n",
    "   - Kernel Size: `3 × 3`, Padding: `1`  \n",
    "   - Components:  \n",
    "     - Batch Normalization  \n",
    "     - ReLU Activation  \n",
    "     - MaxPooling: `2 × 2`  \n",
    "     - Dropout2D: `p = 0.5`\n",
    "\n",
    "3. **Conv Layer 3**  \n",
    "   - Channels: `32 → 64`  \n",
    "   - Kernel Size: `3 × 3`, Padding: `1`  \n",
    "   - Components:  \n",
    "     - Batch Normalization  \n",
    "     - ReLU Activation  \n",
    "     - MaxPooling: `2 × 2`  \n",
    "     - Dropout2D: `p = 0.5`\n",
    "\n",
    "4. **AdaptiveAvgPool2d**  \n",
    "   - Output Size: `7 × 7`  \n",
    "   - Ensures a fixed-size output regardless of input image size variations.\n",
    " \n",
    "5. **Fully Connected Layer 1**  \n",
    "   - Input Features: `64 × 7 × 7 = 3136`  \n",
    "   - Output Features: `512`  \n",
    "   - Components:  \n",
    "     - ReLU Activation  \n",
    "     - Dropout: `p = 0.5`\n",
    "\n",
    "6. **Fully Connected Layer 2**  \n",
    "   - Input Features: `512`  \n",
    "   - Output Features: `2` (one for each class)  \n",
    "\n",
    "7. **Output layer**\n",
    "   - Final output: `2` logits (e.g., for NORMAL and PNEUMONIA)\n",
    "\n",
    "The criterion is ```nn.CrossEntropyLoss```. The criterion has different importances for each class(since the classes are unbalanced), which ensures that the NORMAL class can be fairly tested as well.\n",
    "\n",
    "The optimizer is ```Adam```, due to its stability in convergence, and adaptive learning rates. SGD was another contender, but Adam was choosen in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.pool =  nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropout2d = nn.Dropout2d(0.3)\n",
    "\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.fc1 = nn.Linear(64*7*7,512)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.dropout2d(x)\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout2d(x)\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        x = self.adaptive_pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "        # return torch.argmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "#do weight importance stuff here\n",
    "targets = [label for _, label in train_loader.dataset.get_image_label_pairs()]\n",
    "class_counts = np.bincount(targets)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum()  # Normalize (optional but cleaner)\n",
    "class_weights_tensor = torch.FloatTensor(class_weights)\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(), \n",
    "#     lr=h[\"lr\"],\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=1e-4\n",
    "# )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=h[\"lr\"], weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "The model is trained on a number of epochs(specified by the hyperparameter).\n",
    "Additionally, a validation loss is calculated after every epoch.\n",
    "\n",
    "After training, the train and validation loss per epoch is plotted against the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss(model,val_loader):\n",
    "    loss_function  = torch.nn.functional.cross_entropy\n",
    "    total_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs,labels)\n",
    "            total_loss+=loss\n",
    "    \n",
    "    return total_loss/len(val_loader)\n",
    "\n",
    "def plot_val_test_loss(trainLossHistory,valLossHistory):\n",
    "    temp_train = [i.item() for i in trainLossHistory]\n",
    "    temp_val = [i.item() for i in valLossHistory]\n",
    "    plt.plot(temp_train,label=\"Train loss\")\n",
    "    plt.plot(temp_val,label=\"Validation loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, h):\n",
    "    n_total_steps = len(train_loader)\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    for epoch in range(h[\"num_epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{h['num_epochs']}\", \n",
    "                            leave=False, unit=\"batch\")\n",
    "\n",
    "        for i, (images, labels) in enumerate(progress_bar):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping to avoid exploding gradients\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{h['num_epochs']}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "\n",
    "        val_loss = validation_loss(model, val_loader)\n",
    "        val_loss_history.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{h['num_epochs']}], Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history, val_loss_history = train_model(model,train_loader,val_loader,criterion,optimizer,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model\n",
    "\n",
    "The model is evaluated on the data set aside for testing.\n",
    "\n",
    "The follow metrics are captured/outputed:\n",
    "- Accuracy\n",
    "- F1 score\n",
    "- Precision\n",
    "- Recall\n",
    "\n",
    "These metrics are also done for each class.\n",
    "\n",
    "Lastly, a confusion matrix is outputted to get a visual of how well the model performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, classes):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    class_report = classification_report(true_labels, predicted_labels, target_names=classes)\n",
    "\n",
    "    print(f\"Accuracy on the test set: {accuracy:.2%}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"report\": class_report,\n",
    "        \"true_labels\": true_labels,\n",
    "        \"predicted_labels\": predicted_labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_model(model,test_loader,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(metrics[\"true_labels\"],metrics[\"predicted_labels\"])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"NORMAL\",\"PNEUMONIA\"])\n",
    "\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
